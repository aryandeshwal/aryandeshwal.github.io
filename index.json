[{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor in the Department of Computer Science and Engineering at University of Minnesota, Twin Cities.\nI got my PhD in Computer Science at Washington State University where I was very fortunate to be advised by Dr. Jana Doppa. I also spent three wonderful summers as research intern at Meta and Google.\n-- -- -- My general research interests are in the areas of artificial intelligence (AI) and machine learning (ML) where I focus on advancing foundations of AI/ML to solve challenging real-world problems. The overarching theme of my research program is AI to Accelerate Scientific Discovery and Engineering Design. Specific topics include:   Sequential decision-making under uncertainty (Bayesian optimization and Reinforcement learning) in a data-efficient manner.\n  Probabilistic modeling over combinatorial structured data in small supervised data settings.\n  Applications: accelerate the discovery of nanoporous materials for sustainability applications (e.g., carbon capture and storage/separation of gases); accelerate the design of effective, safe, and low-cost drugs/vaccines; and design of high-performance and low-power hardware to overcome Moore\u0026rsquo;s law.\n  **I'm on the academic job market this season!** --  /* Inline page-local styles for Latest News block on profile */ .profile-news-wrapper { margin-top: 1.5rem; } .profile-news-title { font-size: 1.15rem; font-weight: 600; margin: 0 0 0.5rem; } .profile-news-scroll { max-height: 220px; overflow-y: auto; border-left: 3px solid #e0e0e0; padding-left: 0.75rem; } .profile-news-list { list-style: none; padding: 0; margin: 0; } .profile-news-list li { margin: 0 0 0.6rem 0; } .profile-news-date { font-weight: 600; color: #555; }  Latest News November 2025 - Paper on AI driven adaptive experimental design for discovering 3D printing configurations accepted to IAAI/AAAI 2026.  November 2025 - Paper on offline safe reinforcement learning accepted to NeurIPS 2025. Code  November 2025 - Paper on real-world benchmark for high dimensional Bayesian optimization derived from urban mobility accepted to NeurIPS 2025. Code  September 2025 - Paper on sample-efficient exploration of accuracy-calibration pareto frontier in language models accepted to EMNLP 2025. Code  September 2025 - Tutorial on Black-box Optimization from Offline Datasets accepted at AAAI 2026. September 2025 - Excited to organize the fifth iteration of our Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE) at AAAI 2026. August 2025 - Co-organized the GenAI4Science Workshop: Integrating Scientific Knowledge into Generative AI at the Univesity of Minnesota.  August 2025 - New perspective article on AI enabled scientific revolution capturing the consensus discussed at the second NSF workshop on AI-enabled scientific revolution.     ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://aryandeshwal.github.io/author/aryan-deshwal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aryan-deshwal/","section":"authors","summary":"I am an Assistant Professor in the Department of Computer Science and Engineering at University of Minnesota, Twin Cities.\nI got my PhD in Computer Science at Washington State University where I was very fortunate to be advised by Dr.","tags":null,"title":"Aryan Deshwal","type":"authors"},{"authors":null,"categories":null,"content":"Lecture details and list of relevant reading materials/references for Advanced Machine Learning course (CSCI - 5525) offered at Computer Science and Engineering department, University of Minnesota, Fall 2025.\n Instructor: Aryan Deshwal Time/Location: 02:30 PM ‑ 03:45 PM TTh  Relevant Textbooks\n PRML: Pattern recognition and Machine Learning, Chris Bishop\n Deep Learning: Foundations and Concepts, Chris Bishop and Hugh Bishop\n GPML: Gaussian Processes for Machine Learning, Carl Edward Rasmussen and Christopher K. I. Williams\n PML: Probabilistic Machine Learning: Advanced Topics, Kevin Murphy\n /* Page-local styles for the course table */ .course-table { width: 100%; table-layout: fixed; } .course-table th, .course-table td { vertical-align: top; } .course-table .col-lecture { width: 10%; white-space: nowrap; } .course-table .col-topic { width: 30%; } .course-table .col-refs { width: 60%; } /* Improve wrapping of long URLs in references */ .course-table .col-refs { overflow-wrap: anywhere; word-break: break-word; }    Lecture Topic Reading Materials/References     1 Introduction to Machine Learning and its History  -- Additional Resources: Bernhard Schölkopf's excellent ML history lecture at MLSS 2020    2 Introduction to Probabilistic Modeling with Linear Regression PRML Chapter 1-3, GPML Chapter 1   3 Gaussian Processes and Kernel Methods GPML Chapter 2-4 -- Additional Resources: Dive into Deep Learning Chapter 18 on GPs Kanagawa et al., Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences GpyTorch    4 Generalization, Model selection and Occam's razor GPML Chapter 5 -- Additional Resources: David Mackay's book Chapter 28 Lotfi et al., Bayesian Model Selection, the Marginal Likelihood, and Generalization    5 Bayesian Decision Theory PRML Chapter 1.5 -- Additional Resources: Roman Garnett's Bayesian Optimization Chapter 4 and 5    6 Neural Networks: Learning Representations Bishop Deep Learning Chapter 6    7 Backpropagation and Automatic Differentiation Bishop Deep Learning Chapter 8 -- Additional Resources: Andrej Karpathy's post on backpropagation    8 Stochastic Optimization Bishop Deep Learning Chapter 7   9 Training tips for Neural Networks  Deep Learning Tuning Playbook Andrej Karpathy's A Recipe for Training Neural Networks Experiment Management     10 Attention and Transformers Bishop Deep Learning Chapter 12 -- Additional Resources: Richard Turner's An Introduction to Transformers Simon Institute's Workshop on Transformers Edelman et al, Self-Attention Inductive Bias    11 Deep Latent Variable Models: Variational Autoencoders Murphy PML (Advanced Topics) Chapter 21   12 Diffusion Models Murphy PML (Advanced Topics) Chapter 25   13 Autoregressive Models Murphy PML (Advanced Topics) Chapter 22   14 Reinforcement Learning (RL): Exploration/Exploitation Tradeoff Murphy PML (Advanced Topics) Chapter 22   14 Policy based RL Murphy PML (Advanced Topics) Chapter 22   15 Bayesian Optimization  BoTorch Tutorials     ","date":1756166400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1756166400,"objectID":"36171a282bd4a4733555b8098f4ee992","permalink":"https://aryandeshwal.github.io/courses/csci-5525/","publishdate":"2025-08-26T00:00:00Z","relpermalink":"/courses/csci-5525/","section":"courses","summary":"Graduate-level course in Machine Learning","tags":null,"title":"CSCI 5525 - Advanced Machine Learning","type":"docs"},{"authors":null,"categories":null,"content":"This page hosts materials for CSCI 5980/8980 (AI for Sequential Decision Making), Spring 2025.\n Instructor: Aryan Deshwal Time/Location: TBA  Lectures and References Use the table below. The last column is wider to accommodate many references. Edit rows as needed.\n /* Page-local styles for the course table */ .course-table { width: 100%; table-layout: fixed; } .course-table th, .course-table td { vertical-align: top; } .course-table .col-lecture { width: 10%; white-space: nowrap; } .course-table .col-topic { width: 30%; } .course-table .col-refs { width: 60%; } /* Improve wrapping of long URLs in references */ .course-table .col-refs { overflow-wrap: anywhere; word-break: break-word; }    Lecture Topic References     1     2     3     4     5     6     7     8     9     10     11     12      ","date":1736899200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1736899200,"objectID":"6616ef2865637e20da6a8f4132278ecb","permalink":"https://aryandeshwal.github.io/courses/csci-5980-8980/","publishdate":"2025-01-15T00:00:00Z","relpermalink":"/courses/csci-5980-8980/","section":"courses","summary":"Special topics course on AI for sequential decision making, covering MDPs, RL, offline RL, and Bayesian optimization.","tags":null,"title":"Overview","type":"docs"},{"authors":["Azza Fadhel","Nathaniel W. Zuckschwerdt","Aryan Deshwal","Susmita Bose","Amit Bandyopadhyay","Jana Doppa"],"categories":[],"content":"","date":1770249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"0b60a8e9a7ae588a4a630d9d02f0c392","permalink":"https://aryandeshwal.github.io/publication/fadhel-2025-iaai/","publishdate":"2024-09-03T03:19:28.396322Z","relpermalink":"/publication/fadhel-2025-iaai/","section":"publication","summary":"Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed, and material feed rate) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each input configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper applies the general principle of AI-driven adaptive experimental design for optimization to the more challenging problem of discovering feasible configurations. The key idea is to build a probabilistic surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition (DED) process to print GRCop-42, a high-performance copper–chromium–niobium alloy developed by NASA for extreme-temperature aerospace applications. Within weeks, our approach yielded multiple defect-free outputs across a range of laser powers—dramatically reducing time-to-result and resource expenditure compared to four months of manual experimentation by our collaborators with little to no success. By enabling high-quality GRCop-42 fabrication on readily available infrared laser platforms for the first-time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production of rocket engine chambers, heat exchangers, and other high-heat-flux components.","tags":[],"title":"Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-Driven Adaptive Experimental Design","type":"publication"},{"authors":["Anuj Karpatne","Aryan Deshwal","Xiaowei Jia","Wei Ding","Michael Steinbach","Aidong Zhang","Vipin Kumar"],"categories":[],"content":"","date":1738713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"83e6da4cf1bd482f799b56d7b79dc812","permalink":"https://aryandeshwal.github.io/publication/karpatne-2025-npj/","publishdate":"2024-09-03T03:19:28.396322Z","relpermalink":"/publication/karpatne-2025-npj/","section":"publication","summary":"Artificial intelligence (AI) is transforming science and, in turn, being advanced by scientific challenges. A 2023 NSF-sponsored workshop at NSF Headquarters launched a national dialogue on this synergy. A second NSF-sponsored workshop, held in August 2024 at the University of Minnesota, revisited those insights in light of the GenAI revolution. This report captures key discussions and recommendations to guide the development of GenAI aligned with scientific discovery.","tags":[],"title":"AI-enabled scientific revolution in the age of generative AI - second NSF workshop report","type":"publication"},{"authors":["Gaoxiang Luo","Aryan Deshwal"],"categories":[],"content":"","date":1738713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"e26f8c25a53ddec1248a665a77fe30e4","permalink":"https://aryandeshwal.github.io/publication/luo-2025-emnlp/","publishdate":"2024-09-03T03:19:28.396322Z","relpermalink":"/publication/luo-2025-emnlp/","section":"publication","summary":"Selecting an optimal set of exemplars is critical for good performance of in-context learning. However, prior exemplar search methods narrowly optimize for predictive accuracy, critically neglecting model calibration—a key determinant of trustworthiness and safe deployment. In this paper, we formulate exemplar selection as a multi-objective optimization problem, explicitly targeting both the maximization of predictive accuracy and the minimization of expected calibration error. We solve this problem with a sample-efficient Combinatorial Bayesian Optimization algorithm (COM-BOM) to find the Pareto-front that optimally trade-offs the two objectives of accuracy and calibration. We evaluate COM-BOM on multiple tasks from un-saturated MMLU-pro benchmark and find that COM-BOM beats or matches the baselines in jointly optimizing the two objectives, while requiring a minimal number of LLM API calls.","tags":[],"title":"Bayesian Exemplar Search for Efficiently Exploring the Accuracy-Calibration Pareto Frontier","type":"publication"},{"authors":["Seunghee Ryu","Donghoon Kwon","Seongjin Choi","Aryan Deshwal","Seungmo Kang","Carolina Osorio"],"categories":[],"content":"","date":1738713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"199e0171e1c106b4b7b654bfb06feb43","permalink":"https://aryandeshwal.github.io/publication/ryu-2025-neurips/","publishdate":"2024-09-03T03:19:28.396322Z","relpermalink":"/publication/ryu-2025-neurips/","section":"publication","summary":"We introduce BO4Mob, a new benchmark framework for high-dimensional Bayesian Optimization (BO), driven by the challenge of origin-destination (OD) travel demand estimation in large urban road networks. Estimating OD travel demand from limited traffic sensor data is a difficult inverse optimization problem, particularly in real-world, large-scale transportation networks. This problem involves optimizing over high-dimensional continuous spaces where each objective evaluation is computationally expensive, stochastic, and non-differentiable. BO4Mob comprises five scenarios based on real-world San Jose, CA road networks, with input dimensions scaling up to 10,100. These scenarios utilize high-resolution, open-source traffic simulations that incorporate realistic nonlinear and stochastic dynamics. We demonstrate the benchmark utility by evaluating four optimization methods: three state-of-the-art BO algorithms and one non-BO baseline. This benchmark is designed to support both the development of scalable optimization algorithms and their application for the design of data-driven urban mobility models, including high-resolution digital twins of metropolitan road networks. Code and documentation are available at https://github.com/UMN-Choi-Lab/BO4Mob","tags":[],"title":"BO4Mob - Bayesian Optimization Benchmarks for High-Dimensional Urban Mobility Problem","type":"publication"},{"authors":["Yassine Chemingui","Aryan Deshwal","Alan Fern","Thanh Nguyen-Tang","Jana Doppa"],"categories":[],"content":"","date":1738713600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"9d57bd9402ebf9447ad4d58e4bd1868f","permalink":"https://aryandeshwal.github.io/publication/chemingui-2025-neurips/","publishdate":"2024-09-03T03:19:28.396322Z","relpermalink":"/publication/chemingui-2025-neurips/","section":"publication","summary":"We study the problem of Offline Safe Reinforcement Learning (OSRL), where the goal is to learn a reward-maximizing policy from fixed data under a cumulative cost constraint. We propose a novel OSRL approach that frames the problem as a mini-max objective and solves it by combining offline RL with online optimization algorithms. We prove the approximate optimality of this approach when integrated with an approximate offline RL oracle and no-regret online optimization. We also present a practical approximation that can be combined with any offline RL algorithm, eliminating the need for offline policy evaluation. Empirical results on the DSRL benchmark demonstrate that our method reliably enforces safety constraints under stringent cost budgets, while achieving high rewards.","tags":[],"title":"Online Optimization for Offline Safe Reinforcement Learning","type":"publication"},{"authors":["Yassine Chemingui","Aryan Deshwal","Honghao Wei","Alan Fern","Janardhan Rao Doppa"],"categories":[],"content":"","date":1736035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"691673c7a74fefeeeef1e1171e036b42","permalink":"https://aryandeshwal.github.io/publication/chemingui-2025-aaai/","publishdate":"2024-08-03T03:19:28.396322Z","relpermalink":"/publication/chemingui-2025-aaai/","section":"publication","summary":"Offline safe reinforcement learning (OSRL) involves learning a decision-making policy to maximize rewards from a fixed batch of training data to satisfy pre-defined safety constraints. However, adapting to varying safety constraints during deployment without retraining remains an under-explored challenge. To address this challenge, we introduce constraint-adaptive policy switching (CAPS), a wrapper framework around existing offline RL algorithms. During training, CAPS uses offline data to learn multiple policies with a shared representation that optimize different reward and cost trade-offs. During testing, CAPS switches between those policies by selecting at each state the policy that maximizes future rewards among those that satisfy the current cost constraint. Our experiments on 38 tasks from the DSRL benchmark demonstrate that CAPS consistently outperforms existing methods, establishing a strong wrapper-based baseline for OSRL.","tags":[],"title":"Constraint-Adaptive Policy Switching for Offline Safe Reinforcement Learning","type":"publication"},{"authors":["Aryan Deshwal","Sait Cakmak","Yuhou Xia","David Eriksson"],"categories":[],"content":"","date":1725494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"78c9985826070b9024c01d12a90e5b56","permalink":"https://aryandeshwal.github.io/publication/deshwal-2024-automl/","publishdate":"2024-08-03T03:19:28.396322Z","relpermalink":"/publication/deshwal-2024-automl/","section":"publication","summary":"Bayesian optimization (BO) is a powerful approach to sample-efficient optimization of black-box functions. However, in settings with very few function evaluations, a successful application of BO may require transferring information from historical experiments. These related experiments may not have exactly the same tunable parameters (search spaces), motivating the need for BO with transfer learning for heterogeneous search spaces. In this paper, we propose two methods for this setting. The first approach leverages a Gaussian process (GP) model with a conditional kernel to transfer information between different search spaces. Our second approach treats the missing parameters as hyperparameters of the GP model that can be inferred jointly with the other GP hyperparameters or set to fixed values. We show that these two methods perform well on several benchmark problems.","tags":[],"title":"Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces","type":"publication"},{"authors":["Eric S. Chen","Alaleh Ahmadianshalchi","Sonja S. Sparks","Chuchu Chen","Aryan Deshwal","Janardhan Rao Doppa","Kaiyan Qiu"],"categories":[],"content":"","date":1725408000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662779968,"objectID":"0c30fef7b03dfc2e1ebec709188681b3","permalink":"https://aryandeshwal.github.io/publication/alaleh-2024-amt/","publishdate":"2024-08-02T03:19:28.396322Z","relpermalink":"/publication/alaleh-2024-amt/","section":"publication","summary":"The development of a general-purpose machine learning algorithm capable of quickly identifying optimal 3D-printing settings can save manufacturing time and cost, reduce labor intensity, and improve the quality of 3D-printed objects. Existing methods have limitations which focus on overall performance or one specific aspect of 3D-printing quality. Here, for addressing the limitations, a multi-objective Bayesian Optimization (BO) approach which uses a general-purpose algorithm to optimize the black-box functions is demonstrated and identifies the optimal input parameters of direct ink writing for 3D-printing different presurgical organ models with intricate geometry. The BO approach enhances the 3D-printing efficiency to achieve the best possible printed object quality while simultaneously addressing the inherent trade-offs from the process of pursuing ideal outcomes relevant to requirements from practitioners. The BO approach also enables us to effectively explore 3D-printing inputs inclusive of layer height, nozzle travel speed, and dispensing pressure, as well as visualize the trade-offs between each set of 3D-printing inputs in terms of the output objectives which consist of time, porosity, and geometry precisions through the Pareto front.","tags":[],"title":"Machine Learning Enabled Design and Optimization for 3D‐Printing of High‐Fidelity Presurgical Organ Models","type":"publication"},{"authors":["Minh Hoang","Azza Fadhel","Aryan Deshwal","Jana Doppa","Trong Nghia Hoang"],"categories":[],"content":"","date":1725321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693568,"objectID":"a62b5ba15790c908a6cf7ed10c15ea00","permalink":"https://aryandeshwal.github.io/publication/minh-2024-icml/","publishdate":"2023-09-22T03:19:28.396322Z","relpermalink":"/publication/minh-2024-icml/","section":"publication","summary":"Offline design optimization problem arises in numerous science and engineering applications including material and chemical design, where expensive online experimentation necessitates the use of in silico surrogate functions to predict and maximize the target objective over candidate designs. Although these surrogates can be learned from offline data, their predictions are often inaccurate outside the offline data regime. This challenge raises a fundamental question about the impact of imperfect surrogate model on the performance gap between its optima and the true optima, and to what extent the performance loss can be mitigated. Although prior work developed methods to improve the robustness of surrogate models and their associated optimization processes, a provably quantifiable relationship between an imperfect surrogate and the corresponding performance gap, as well as whether prior methods directly address it, remain elusive. To shed light on this important question, we present a theoretical framework to understand offline black-box optimization, by explicitly bounding the optimization quality based on how well the surrogate matches the latent gradient field that underlines the offline data. Inspired by our theoretical analysis, we propose a principled black-box gradient matching algorithm to create effective surrogate models for offline optimization, improving over prior approaches on various real-world benchmarks.","tags":[],"title":"Learning Surrogates for Offline Black-Box Optimization via Gradient Matching","type":"publication"},{"authors":["Mohammed Amine Gharsallaoui","Bhupinderjeet Singh","Supriya Savalkar","Aryan Deshwal","Yan Yan","Ananth Kalyanaraman","Kirti Rajagopalan","Janardhan Rao Doppa"],"categories":[],"content":"","date":1725235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693568,"objectID":"f3953b66c1cfbe52fa4313adc95c1a15","permalink":"https://aryandeshwal.github.io/publication/amine-2024-ijcai/","publishdate":"2023-09-22T03:19:28.396322Z","relpermalink":"/publication/amine-2024-ijcai/","section":"publication","summary":"Predicting the spatiotemporal variation in streamflow along with uncertainty quantification enables decision-making for sustainable management of scarce water resources. Process-based hydrological models (aka physics-based models) are based on physical laws, but using simplifying assumptions which can lead to poor accuracy. Data-driven approaches offer a powerful alternative, but they require large amount of training data and tend to produce predictions that are inconsistent with physical laws. This paper studies a constrained reasoning and learning (CRL) approach where physical laws represented as logical constraints are integrated as a layer in the deep neural network. To address small data setting, we develop a theoretically-grounded training approach to improve the generalization accuracy of deep models. For uncertainty quantification, we combine the synergistic strengths of Gaussian processes (GPs) and deep temporal models (i.e., deep models for time-series forecasting) by passing the learned latent representation as input to a standard distance-based kernel. Experiments on multiple real-world datasets demonstrate the effectiveness of both CRL and GP with deep kernel approaches over strong baseline methods.","tags":[],"title":"Streamflow Prediction with Uncertainty Quantification for Water Management","type":"publication"},{"authors":["Yassine Chemingui","Aryan Deshwal","Nghia Hoang","Janardhan Rao Doppa"],"categories":[],"content":"","date":1725148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693568,"objectID":"3a26a4b8db198b19619e48f69181bc7e","permalink":"https://aryandeshwal.github.io/publication/yassine-2023-pgs/","publishdate":"2023-09-22T03:19:28.396322Z","relpermalink":"/publication/yassine-2023-pgs/","section":"publication","summary":"Offline optimization is an emerging problem in many experimental engineering domains including protein, drug or aircraft design, where online experimentation to collect evaluation data is too expensive or dangerous. To avoid that, one has to optimize an unknown function given only its offline evaluation at a fixed set of inputs. A naive solution to this problem is to learn a surrogate model of the unknown function and optimize this surrogate instead. However, such a naive optimizer is prone to erroneous overestimation of the surrogate (possibly due to over-fitting on a biased sample of function evaluation) on inputs outside the offline dataset. Prior approaches addressing this challenge have primarily focused on learning robust surrogate models. However, their search strategies are derived from the surrogate model rather than the actual offline data. To fill this important gap, we introduce a new learning-to-search perspective for offline optimization by reformulating it as an offline reinforcement learning problem. Our proposed policy-guided gradient search approach explicitly learns the best policy for a given surrogate model created from the offline data. Our empirical results on multiple benchmarks demonstrate that the learned optimization policy can be combined with existing offline surrogates to significantly improve the optimization performance.","tags":[],"title":"Offline Model-based Black-Box Optimization via Policy-guided Gradient Search","type":"publication"},{"authors":["Nickolas Gantzler","Aryan Deshwal","Janardhan Rao Doppa","Cory Simon"],"categories":[],"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693568,"objectID":"d00892beff14a19a0b8cb2a527c9472d","permalink":"https://aryandeshwal.github.io/publication/nick-2023-dd/","publishdate":"2022-09-22T03:19:28.396322Z","relpermalink":"/publication/nick-2023-dd/","section":"publication","summary":"Our objective is to search a large candidate set of covalent organic frameworks (COFs) for the one with the largest equilibrium adsorptive selectivity for xenon (Xe) over krypton (Kr) at room temperature. To predict the Xe/Kr selectivity of a COF structure, we have access to two molecular simulation techniques: (1) a higher-fidelity, binary grand canonical Monte Carlo simulation and (2) a lower-fidelity Henry coefficient calculation that (a) approximates the adsorbed phase as dilute and, consequently, (b) incurs a smaller computational runtime than the higher-fidelity simulation. To efficiently search for the COF with the largest high-fidelity Xe/Kr selectivity, we employ a multi-fidelity Bayesian optimization (MFBO) approach. MFBO constitutes a sequential, automated feedback loop of (1) conduct a low- or high-fidelity molecular simulation of Xe/Kr adsorption in a COF, (2) use the simulation data gathered thus far to train a surrogate model that cheaply predicts, with quantified uncertainty, the low- and high-fidelity simulated Xe/Kr selectivity of COFs from their structural/chemical features, and then (3) plan the next simulation (i.e., choose the next COF and fidelity) in consideration of balancing exploration, exploitation, and cost. We find that MFBO acquires the optimal COF among the candidate set of 609 structures using only 38 low-fidelity and nine high-fidelity simulations, incurring only 2.5%, 5% on average, and 18% on average of the computational runtime of an exhaustive, random, and single-fidelity BO search, respectively.","tags":[],"title":"Multi-fidelity Bayesian Optimization of Covalent Organic Frameworks for Xenon/Krypton Separations","type":"publication"},{"authors":["Aryan Deshwal","Sebastian Ament","Maximilian Balandat","Eytan Bakshy","Janardhan Rao Doppa","David Eriksson"],"categories":[],"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693568,"objectID":"087784f000f78256e3e88a52b5416b18","permalink":"https://aryandeshwal.github.io/publication/deshwal-2023-aistats/","publishdate":"2022-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2023-aistats/","section":"publication","summary":"We consider the problem of optimizing expensive black-box functions over high-dimensional combinatorial spaces which arises in many science, engineering, and ML applications. We use Bayesian Optimization (BO) and propose a novel surrogate modeling approach for efficiently handling a large number of binary and categorical parameters. The key idea is to select a number of discrete structures from the input space (the dictionary) and use them to define an ordinal embedding for high-dimensional combinatorial structures. This allows us to use existing Gaussian process models for continuous spaces. We develop a principled approach based on binary wavelets to construct dictionaries for binary spaces, and propose a randomized construction method that generalizes to categorical spaces. We provide theoretical justification to support the effectiveness of the dictionary-based embeddings. Our experiments on diverse real-world benchmarks demonstrate the effectiveness of our proposed surrogate modeling approach over state-of-the-art BO methods.","tags":[],"title":"Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings","type":"publication"},{"authors":["Ryan-Rhys Griffiths, et al"],"categories":[],"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693568,"objectID":"bf8ae3d47b85cf0073302ed3965ca7f8","permalink":"https://aryandeshwal.github.io/publication/gauche-2023-neurips/","publishdate":"2022-09-22T03:19:28.396322Z","relpermalink":"/publication/gauche-2023-neurips/","section":"publication","summary":"We introduce GAUCHE, a library for GAUssian processes in CHEmistry. Gaussian processes have long been a cornerstone of probabilistic machine learning, affording particular advantages for uncertainty quantification and Bayesian optimisation. Extending Gaussian processes to chemical representations, however, is nontrivial, necessitating kernels defined over structured inputs such as graphs, strings and bit vectors. By defining such kernels in GAUCHE, we seek to open the door to powerful tools for uncertainty quantification and Bayesian optimisation in chemistry. Motivated by scenarios frequently encountered in experimental chemistry, we showcase applications for GAUCHE in molecular discovery and chemical reaction optimisation. The codebase is made available at https://github.com/leojklarner/gauche","tags":[],"title":"Gauche - A Library for Gaussian Processes in Chemistry","type":"publication"},{"authors":["Gaurav Narang","Aryan Deshwal","Raid Ayoub","Michael Kishinevsky","Janardhan Rao Doppa","Partha Pratim Pande"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662693028,"objectID":"79cb1b350925fb3fe623811cecaacb7d","permalink":"https://aryandeshwal.github.io/publication/gaurav-2023-todaes/","publishdate":"2022-09-22T03:10:28.396322Z","relpermalink":"/publication/gaurav-2023-todaes/","section":"publication","summary":"The complexity of manycore System-on-chips (SoCs) is growing faster than our ability to manage them to reduce the overall energy consumption. Further, as SoC design moves toward three-dimensional (3D) architectures, the core's power density increases leading to unacceptable high peak chip temperatures. In this article, we consider the optimization problem of dynamic power management (DPM) in manycore SoCs for an allowable performance penalty (say, 5%) and admissible peak chip temperature. We employ a machine learning– (ML) based DPM policy, which selects the voltage/frequency levels for different cluster of cores as a function of the application workload features such as core computation and inter-core traffic, and so on. We propose a novel learning-to-search (L2S) framework to automatically identify an optimized sequence of DPM decisions from a large combinatorial space for joint energy-thermal optimization for one or more given applications. The optimized DPM decisions are given to a supervised learning algorithm to train a DPM policy, which mimics the corresponding decision-making behavior. Our experiments on two different manycore architectures designed using wireless interconnect and monolithic 3D demonstrate that principles behind the L2S framework are applicable for more than one configuration. Moreover, L2S-based DPM policies achieve up to 30% energy-delay product savings and reduce the peak chip temperature by up to 17 °C compared to the state-of-the-art ML methods for an allowable performance overhead of only 5%.","tags":[],"title":"Dynamic Power Management in Large Manycore Systems - A Learning-to-Search Framework","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa","Dae Hyun Kim"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631157568,"objectID":"5e1ac7af9a6724773ff50e0a994054b3","permalink":"https://aryandeshwal.github.io/publication/deshwal-2022-aaai/","publishdate":"2021-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2022-aaai/","section":"publication","summary":"Optimizing expensive to evaluate black-box functions over an input space consisting of all permutations of d objects is an important problem with many real-world applications. For example, placement of functional blocks in hardware design to optimize performance via simulations. The overall goal is to minimize the number of function evaluations to find high-performing permutations. The key challenge in solving this problem using the Bayesian optimization (BO) framework is to trade-off the complexity of statistical model and tractability of acquisition function optimization. In this paper, we propose and evaluate two algorithms for BO over Permutation Spaces (BOPS). First, BOPS-T employs Gaussian process (GP) surrogate model with Kendall kernels and a Tractable acquisition function optimization approach based on Thompson sampling to select the sequence of permutations for evaluation. Second, BOPS-H employs GP surrogate model with Mallow kernels and a Heuristic search approach to optimize expected improvement acquisition function. We theoretically analyze the performance of BOPS-T to show that their regret grows sub-linearly. Our experiments on multiple synthetic and real-world benchmarks show that both BOPS-T and BOPS-H perform better than the state-of-the-art BO algorithm for combinatorial spaces. To drive future research on this important problem, we make new resources and real-world benchmarks available to the community.","tags":[],"title":"Bayesian Optimization over Permutation Spaces","type":"publication"},{"authors":["Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"89afcfa46f2a929fbbdffe67daab738e","permalink":"https://aryandeshwal.github.io/publication/deshwal-2021-neurips/","publishdate":"2021-10-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2021-neurips/","section":"publication","summary":"We consider the problem of optimizing combinatorial spaces (e.g., sequences, trees, and graphs) using expensive black-box function evaluations. For example, optimizing molecules for drug design using physical lab experiments. Bayesian optimization (BO) is an efficient framework for solving such problems by intelligently selecting the inputs with high utility guided by a learned surrogate model. A recent BO approach for combinatorial spaces is through a reduction to BO over continuous spaces by learning a latent representation of structures using deep generative models (DGMs). The selected input from the continuous space is decoded into a discrete structure for performing function evaluation. However, the surrogate model over the latent space only uses the information learned by the DGM, which may not have the desired inductive bias to approximate the target black-box function. To overcome this drawback, this paper proposes a principled approach referred as LADDER. The key idea is to define a novel structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Our experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method, and performs better or similar to state-of-the-art methods.","tags":[],"title":"Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces","type":"publication"},{"authors":["Aryan Deshwal","Cory Simon","Janardhan Rao Doppa"],"categories":[],"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631157568,"objectID":"72b79ec3e155926d8cc8685daabcbde1","permalink":"https://aryandeshwal.github.io/publication/deshwal-2021-mofs/","publishdate":"2021-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2021-mofs/","section":"publication","summary":"Nanoporous materials (NPMs) could be used to store, capture, and sense many different gases. Given an adsorption task, we often wish to search a library of NPMs for the one with the optimal adsorption property. The high cost of NPM synthesis and gas adsorption measurements, whether these experiments are in the lab or in a simulation, often precludes exhaustive search. We explain, demonstrate, and advocate Bayesian optimization (BO) to actively search for the optimal NPM in a library of NPMs-- and find it using the fewest experiments. The two ingredients of BO are a surrogate model and an acquisition function. The surrogate model is a probabilistic model reflecting our beliefs about the NPM-structure--property relationship based on observations from past experiments. The acquisition function uses the surrogate model to score each NPM according to the utility of picking it for the next experiment. It balances two competing goals: (a) exploitation of our current approximation of the structure-property relationship to pick the highest-performing NPM, and (b) exploration of blind spots in the NPM space to pick an NPM we are uncertain about, to improve our approximation of the structure-property relationship. We demonstrate BO by searching an open database of ~70,000 hypothetical covalent organic frameworks (COFs) for the COF with the highest simulated methane deliverable capacity. BO finds the optimal COF and acquires 30% of the top 100 highest-ranked COFs after evaluating only ~120 COFs. More, BO searches more efficiently than evolutionary and one-shot supervised machine learning approaches.","tags":[],"title":"Bayesian Optimization of Nanoporous Materials","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"2466195aac1dc51ad7b0b4167e878f19","permalink":"https://aryandeshwal.github.io/publication/belakaria-2021-journal/","publishdate":"2021-09-22T03:19:27.654687Z","relpermalink":"/publication/belakaria-2021-journal/","section":"publication","summary":"We consider the problem of black-box multi-objective optimization (MOO) using expensive function evaluations (also referred to as experiments), where the goal is to approximate the true Pareto set of solutions by minimizing the total resource cost of experiments. For example, in hardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive computational simulations. The key challenge is to select the sequence of experiments to uncover high-quality solutions using minimal resources. In this paper, we propose a general framework for solving MOO problems based on the principle of output space entropy (OSE) search: select the experiment that maximizes the information gained per unit resource cost about the true Pareto front. We appropriately instantiate the principle of OSE search to derive efficient algorithms for the following four MOO problem settings: 1) The most basic em single-fidelity setting, where experiments are expensive and accurate; 2) Handling em black-box constraints} which cannot be evaluated without performing experiments; 3) The discrete multi-fidelity setting, where experiments can vary in the amount of resources consumed and their evaluation accuracy; and 4) The em continuous-fidelity setting, where continuous function approximations result in a huge space of experiments. Experiments on diverse synthetic and real-world benchmarks show that our OSE search based algorithms improve over state-of-the-art methods in terms of both computational-efficiency and accuracy of MOO solutions.","tags":[],"title":"Output Space Entropy Search Framework for Multi-Objective Bayesian Optimization","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623208768,"objectID":"02a33ce1e993c9713fd278335b2eb4dd","permalink":"https://aryandeshwal.github.io/publication/deshwal-2021-icml/","publishdate":"2020-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2021-icml/","section":"publication","summary":"We consider the problem of optimizing hybrid structures (mixture of discrete and continuous input variables) via expensive black-box function evaluations. This problem arises in many real-world applications. For example, in materials design optimization via lab experiments, discrete and continuous variables correspond to the presence/absence of primitive elements and their relative concentrations respectively. The key challenge is to accurately model the complex interactions between discrete and continuous variables. In this paper, we propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by utilizing diffusion kernels, which are naturally defined over continuous and discrete variables. We develop a principled approach for constructing diffusion kernels over hybrid spaces by utilizing the additive kernel formulation, which allows additive interactions of all orders in a tractable manner. We theoretically analyze the modeling strength of additive hybrid kernels and prove that it has the universal approximation property. Our experiments on synthetic and six diverse real-world benchmarks show that HyBO significantly outperforms the state-of-the-art methods.","tags":[],"title":"Bayesian Optimization over Hybrid Spaces","type":"publication"},{"authors":["Biresh Kumar Joardar","Aryan Deshwal","Janardhan Rao Doppa","Partha Pratim Pande","Krishnendu Chakrabarty"],"categories":[],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620530368,"objectID":"0704c99ab051c394785f31a88ae5e541","permalink":"https://aryandeshwal.github.io/publication/joardar-2021-tcad/","publishdate":"2020-09-22T03:19:28.396322Z","relpermalink":"/publication/joardar-2021-tcad/","section":"publication","summary":"Resistive random-access memory (ReRAM)-based architectures can be used to accelerate Convolutional Neural Network (CNN) training. However, existing architectures either do not support normalization at all or they support only a limited version of it. Moreover, it is common practice for CNNs to add normalization layers after every convolution layer. In this work, we show that while normalization layers are necessary to train deep CNNs, only a few such layers are sufficient for effective training. A large number of normalization layers do not improve prediction accuracy; it necessitates additional hardware and gives rise to performance bottlenecks. To address this problem, we propose DeepTrain, a heterogeneous architecture enabled by a Bayesian optimization (BO) methodology; together, they provide adequate hardware and software support for normalization operations. The proposed BO methodology determines the minimum number of normalization operations necessary for a given CNN. Experimental evaluation indicates that the BO-enabled DeepTrain architecture achieves up to 15X speed-up compared to a conventional GPU for training CNNs with no accuracy loss while utilizing only a few normalization layers.","tags":[],"title":"High-Throughput Training of Deep CNNs on ReRAM-based Heterogeneous Architectures via Optimized Normalization Layers","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Ganapati Bhat","Janardhan Rao Doppa","Partha Pratim Pande"],"categories":[],"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620530368,"objectID":"c3c42f86b4636a106bd8bfc93c9d69bc","permalink":"https://aryandeshwal.github.io/publication/deshwal-2021-dac/","publishdate":"2020-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2021-dac/","section":"publication","summary":"Mobile system-on-chips (SoCs) are growing in their complexity and heterogeneity (e.g., Arm Big-Little architecture) to meet the needs of emerging applications, including games and artificial intelligence. This makes it very challenging to optimally manage the resources (e.g., controlling the number and frequency of different types of cores) at runtime to meet the desired trade-offs among multiple objectives such as performance and energy. This paper proposes a novel information-theoretic framework referred to as PaRMIS to create Pareto-optimal resource management policies for given target applications and design objectives. PaRMIS specifies parametric policies to manage resources and learns statistical models from candidate policy evaluation data in the form of target design objective values. The key idea is to select a candidate policy for evaluation in each iteration guided by statistical models that maximize the information gain about the true Pareto front. Experiments on a commercial heterogeneous SoC show that PaRMIS achieves better Pareto fronts and is easily usable to optimize complex objectives (e.g., performance per Watt) when compared to prior methods.","tags":[],"title":"Learning Pareto-Frontier Resource Management Policies for Heterogeneous SoCs - An Information-Theoretic Approach","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa"],"categories":[],"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"af3d3f542c5f33cca6ac2a26d89a758a","permalink":"https://aryandeshwal.github.io/publication/deshwal-2021-aaai/","publishdate":"2020-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2021-aaai/","section":"publication","summary":"Bayesian optimization (BO) is an efficient framework for solving black-box optimization problems with expensive function evaluations. This paper addresses the BO problem setting for combinatorial spaces (e.g., sequences and graphs) that occurs naturally in science and engineering applications. A prototypical example is molecular optimization guided by expensive experiments. The key challenge is to balance the complexity of statistical models and tractability of search to select combinatorial structures for evaluation. In this paper, we propose an efficient approach referred as Mercer Features for Combinatorial Bayesian Optimization (MerCBO). The key idea behind MerCBO is to provide explicit feature maps for diffusion kernels over discrete objects by exploiting the structure of their combinatorial graph representation. These Mercer features combined with Thompson sampling as the acquisition function allows us to employ efficient solvers for finding the next structure for evaluation. Experimental evaluation on diverse real-world benchmarks demonstrates that MerCBO performs similarly or better than prior methods.","tags":[],"title":"Mercer Features for Efficient Combinatorial Bayesian Optimization","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"359743054050ff7671318778ccdf7813","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-imoca/","publishdate":"2020-09-22T03:19:28.544737Z","relpermalink":"/publication/belakaria-2020-imoca/","section":"publication","summary":"Many real-world applications involve black-box optimization of multiple objectives using continuous function approximations that trade-off accuracy and resource cost of evaluation. For example, in rocket launching research, we need to find designs that trade-off return-time and angular distance using continuous-fidelity simulators (eg, varying tolerance parameter to trade-off simulation time and accuracy) for design evaluations. The goal is to approximate the optimal Pareto set by minimizing the cost for evaluations. In this paper, we propose a novel approach referred to as information-Theoretic Multi-Objective Bayesian Optimization with Continuous Approximations (iMOCA)} to solve this problem. The key idea is to select the sequence of input and function approximations for multiple objectives which maximize the information gain per unit cost for the optimal Pareto front. Our experiments on diverse synthetic and real-world benchmarks show that iMOCA significantly improves over existing single-fidelity methods.","tags":[],"title":"Information-Theoretic Multi-Objective Bayesian Optimization with Continuous Approximations","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"295333d5728daa4eee65a2976139db9d","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-max/","publishdate":"2020-09-22T03:19:28.544737Z","relpermalink":"/publication/belakaria-2020-max/","section":"publication","summary":"We consider the problem of constrained multi-objective blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto set of solutions satisfying a set of constraints while minimizing the number of function evaluations. For example, in aviation power system design applications, we need to find the designs that trade-off total energy and the mass while satisfying specific thresholds for motor temperature and voltage of cells. This optimization requires performing expensive computational simulations to evaluate designs. In this paper, we propose a new approach referred as {\\em Max-value Entropy Search for Multi-objective Optimization with Constraints (MESMOC)} to solve this problem. MESMOC employs an output-space entropy based acquisition function to efficiently select the sequence of inputs for evaluation to uncover high-quality pareto-set solutions while satisfying constraints.","tags":[],"title":"Max-value Entropy Search for Multi-Objective Bayesian Optimization with Constraints","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa"],"categories":[],"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"0e9cc8055f0bf41b2a977cb2b7d665ec","permalink":"https://aryandeshwal.github.io/publication/deshwal-2020-scalable/","publishdate":"2020-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2020-scalable/","section":"publication","summary":"We study the problem of optimizing expensive blackbox functions over combinatorial spaces (eg, sets, sequences, trees, and graphs). BOCS (Baptista and Poloczek, 2018) is a state-of-the-art Bayesian optimization method for tractable statistical models, which performs semi-definite programming based acquisition function optimization (AFO) to select the next structure for evaluation. Unfortunately, BOCS scales poorly for large number of binary and/or categorical variables. Based on recent advances in submodular relaxation (Ito and Fujimaki, 2016) for solving Binary Quadratic Programs, we study an approach referred as Parametrized Submodular Relaxation (PSR) towards the goal of improving the scalability and accuracy of solving AFO problems for BOCS model. PSR approach relies on two key ideas. First, reformulation of AFO problem as submodular relaxation with some unknown parameters, which can be solved efficiently using minimum graph cut algorithms. Second, construction of an optimization problem to estimate the unknown parameters with close approximation to the true objective. Experiments on diverse benchmark problems show significant improvements with PSR for BOCS model.","tags":[],"title":"Scalable Combinatorial Bayesian Optimization with Tractable Statistical models","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa","Alan Fern"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"88610b44a62fef0adca546957ddbb222","permalink":"https://aryandeshwal.github.io/publication/deshwal-2020-optimizing/","publishdate":"2020-09-22T03:19:27.051221Z","relpermalink":"/publication/deshwal-2020-optimizing/","section":"publication","summary":"We consider the problem of optimizing expensive black-box functions over discrete spaces (e.g., sets, sequences, graphs). The key challenge is to select a sequence of combinatorial structures to evaluate, in order to identify high-performing structures as quickly as possible. Our main contribution is to introduce and evaluate a new learning-to-search framework for this problem called L2S-DISCO. The key insight is to employ search procedures guided by control knowledge at each step to select the next structure and to improve the control knowledge as new function evaluations are observed. We provide a concrete instantiation of L2S-DISCO for local search procedure and empirically evaluate it on diverse real-world benchmarks. Results show the efficacy of L2S-DISCO over state-of-the-art algorithms in solving complex optimization problems.","tags":[],"title":"Optimizing Discrete Spaces via Expensive Evaluations: A Learning to Search Framework","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Nitthilan Kannappan Jayakodi","Janardhan Rao Doppa"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"eda852a119c77f125376cbdaf593eb62","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-uncertainty/","publishdate":"2020-09-22T03:19:26.897879Z","relpermalink":"/publication/belakaria-2020-uncertainty/","section":"publication","summary":"We consider the problem of multi-objective (MO) blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto set of solutions while minimizing the number of function evaluations. For example, in hardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive simulations. We propose a novel uncertainty-aware search framework referred to as USeMO to efficiently select the sequence of inputs for evaluation to solve this problem. The selection method of USeMO consists of solving a cheap MO optimization problem via surrogate models of the true functions to identify the most promising candidates and picking the best candidate based on a measure of uncertainty. We also provide theoretical analysis to characterize the efficacy of our approach. Our experiments on several synthetic and six diverse real-world benchmark problems show that USeMO consistently outperforms the state-of-the-art algorithms.","tags":[],"title":"Uncertainty-Aware Search Framework for Multi-Objective Bayesian Optimization","type":"publication"},{"authors":["Nitthilan Kanappan Jayakodi","Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"adb1692a9c85784bf5062f8cd67085df","permalink":"https://aryandeshwal.github.io/publication/jayakodi-2020-design/","publishdate":"2020-09-22T03:19:27.353414Z","relpermalink":"/publication/jayakodi-2020-design/","section":"publication","summary":"Many real-world edge applications including object detection, robotics, and smart health are enabled by deploying deep neural networks (DNNs) on energy-constrained mobile platforms. In this article, we propose a novel approach to trade off energy and accuracy of inference at runtime using a design space called Learning Energy Accuracy Tradeoff Networks (LEANets). The key idea behind LEANets is to design classifiers of increasing complexity using pretrained DNNs to perform input-specific adaptive inference. The accuracy and energy consumption of the adaptive inference scheme depends on a set of thresholds, one for each classifier. To determine the set of threshold vectors to achieve different energy and accuracy tradeoffs, we propose a novel multiobjective optimization approach. We can select the appropriate threshold vector at runtime based on the desired tradeoff. We perform experiments on multiple pretrained DNNs including ConvNet, VGG-16, and MobileNet using diverse image classification datasets. Our results show that we get up to a 50% gain in energy for negligible loss in accuracy, and optimized LEANets achieve significantly better energy and accuracy tradeoff when compared to a state-of-the-art method referred to as Slimmable neural networks.","tags":[],"title":"Design and Optimization of Energy-Accuracy Tradeoff Networks for Mobile Platforms via Pretrained Deep Models","type":"publication"},{"authors":["Zhiyuan Zhou","Syrine Belakaria","Aryan Deshwal","Wookpyo Hong","Janardhan Rao Doppa","Partha Pratim Pande","Deukhyoun Heo"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"fd224535a9c80060fe0c8d5ce6fa0083","permalink":"https://aryandeshwal.github.io/publication/zhou-2020-design/","publishdate":"2020-09-22T03:19:27.953852Z","relpermalink":"/publication/zhou-2020-design/","section":"publication","summary":"Efficiency of power management system (PMS) is one of the key performance metrics for highly integrated system on chips (SoCs). Towards the goal of improving power efficiency of SoCs, we make two key technical contributions in this paper. First, we develop a multi-output switched-capacitor voltage regulator (SCVR) with a new flying capacitor crossing technique (FCCT) and cloud-capacitor method. Second, to optimize the design parameters of SCVR, we introduce a novel machine¬learning (ML)-inspired optimization framework to reduce the number of expensive design simulations. Simulation shows that power loss of the multi-output SCVR with FCCT is reduced by more than 40% compared to conventional multiple single-output SCVRs. Our ML-based design optimization framework is able to achieve more than 90% reduction in the number of simulations needed to uncover optimized circuit parameters of the proposed SCVR.","tags":[],"title":"Design of Multi-Output Switched-Capacitor Voltage Regulator via Machine Learning","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"182464307b30921802ca781af344ea84","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-mf-osemo/","publishdate":"2020-09-22T03:19:26.897879Z","relpermalink":"/publication/belakaria-2020-mf-osemo/","section":"publication","summary":"We study the novel problem of blackbox optimization of multiple objectives via multi-fidelity function evaluations that vary in the amount of resources consumed and their accuracy. The overall goal is to approximate the true Pareto set of solutions by minimizing the resources consumed for function evaluations. For example, in power system design optimization, we need to find designs that trade-off cost, size, efficiency, and thermal tolerance using multi-fidelity simulators for design evaluations. In this paper, we propose a novel approach referred as Multi-Fidelity Output Space Entropy Search for Multi-objective Optimization (MF-OSEMO) to solve this problem. The key idea is to select the sequence of candidate input and fidelity-vector pairs that maximize the information gained about the true Pareto front per unit resource cost. Our experiments on several synthetic and real-world benchmark problems show that MF-OSEMO, with both approximations, significantly improves over the state-of-the-art single-fidelity algorithms for multi-objective optimization.","tags":[],"title":"Multi-Fidelity Multi-Objective Bayesian Optimization, An Output Space Entropy Search Approach","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"0290f2246eae4bfabca526ce064c5075","permalink":"https://aryandeshwal.github.io/publication/belakaria-2019-max/","publishdate":"2020-09-22T03:19:27.654687Z","relpermalink":"/publication/belakaria-2019-max/","section":"publication","summary":"We consider the problem of multi-objective (MO) blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto-set of solutions by minimizing the number of function evaluations. For example, in hardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive simulations. We propose a novel approach referred to as Max-value Entropy Search for Multi-objective Optimization (MESMO) to solve this problem. MESMO employs an output-space entropy based acquisition function to efficiently select the sequence of inputs for evaluation for quickly uncovering high-quality solutions. We also provide theoretical analysis to characterize the efficacy of MESMO. Our experiments on several synthetic and real-world benchmark problems show that MESMO consistently outperforms state-of-the-art algorithms.","tags":[],"title":"Max-value Entropy Search for Multi-Objective Bayesian Optimization","type":"publication"},{"authors":["Aryan Deshwal","Nitthilan Kanappan Jayakodi","Biresh Kumar Joardar","Janardhan Rao Doppa","Partha Pratim Pande"],"categories":[],"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"51d35b8323c435d311a7763d844a52d0","permalink":"https://aryandeshwal.github.io/publication/deshwal-2019-moos/","publishdate":"2020-09-22T03:19:27.507104Z","relpermalink":"/publication/deshwal-2019-moos/","section":"publication","summary":"The growing needs of emerging applications has posed significant challenges for the design of optimized manycore systems. Network-on-Chip (NoC) enables the integration of a large number of processing elements (PEs) in a single die. To design optimized manycore systems, we need to establish suitable trade-offs among multiple objectives including power, performance, and thermal. Therefore, we consider multi-objective design space exploration (MO-DSE) problems arising in the design of NoC-enabled manycore systems: placement of PEs and communication links to optimize two or more objectives (e.g., latency, energy, and throughput). Existing algorithms to solve MO-DSE problems suffer from scalability and accuracy challenges as size of the design space and the number of objectives grow. In this paper, we propose a novel framework referred as Multi-Objective Optimistic Search (MOOS) that performs adaptive design space exploration using a data-driven model to improve the speed and accuracy of multi-objective design optimization process. We apply MOOS to design both 3D heterogeneous and homogeneous manycore systems using Rodinia, PARSEC, and SPLASH2 benchmark suites. We demonstrate that MOOS improves the speed of finding solutions compared to state-of-the-art methods by up to 13X while uncovering designs that are up to 20% better in terms of NoC. The optimized 3D manycore systems improve the EDP up to 38% when compared to 3D mesh-based designs optimized for the placement of PEs.","tags":[],"title":"MOOS: A multi-objective design space exploration and optimization framework for NoC enabled manycore systems","type":"publication"},{"authors":["Aryan Deshwal","Janardhan Rao Doppa","Dan Roth"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744766,"objectID":"2abaf7694b4cbf1967451ac686ce8a17","permalink":"https://aryandeshwal.github.io/publication/deshwal-2019-learning/","publishdate":"2020-09-22T03:19:26.612542Z","relpermalink":"/publication/deshwal-2019-learning/","section":"publication","summary":"In a structured prediction problem, one needs to learn a predictor that, given a structured input, produces a structured object, such as a sequence, tree, or clustering output. Prototypical structured prediction tasks include part-of-speech tagging (predicting POS tag sequence for an input sentence) and semantic segmentation of images (predicting semantic labels for pixels of an input image). Unlike simple classification problems, here there is a need to assign values to multiple output variables accounting for the dependencies between them. Consequently, the prediction step itself (aka “inference” or “decoding”) is computationally-expensive, and so is the learning process, that typically requires making predictions as part of it. The key learning and inference challenge is due to the exponential size of the structured output space and depend on its complexity. In this paper, we present a unifying perspective of the different frameworks that address structured prediction problems and compare them in terms of their strengths and weaknesses. We also discuss important research directions including integration of deep learning advances into structured prediction methods, and learning from weakly supervised signals and active querying to overcome the challenges of building structured predictors from small amount of labeled data.","tags":[],"title":"Learning and inference for structured prediction: a unifying perspective","type":"publication"},{"authors":["Chao Ma","FA Rezaur Rahman Chowdhury","Aryan Deshwal","Md Rakibul Islam","Janardhan Rao Doppa","Dan Roth"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"612ea79ca4b8ed761a5a0042b3e71ece","permalink":"https://aryandeshwal.github.io/publication/ma-2019-randomized/","publishdate":"2020-09-22T03:19:27.20383Z","relpermalink":"/publication/ma-2019-randomized/","section":"publication","summary":"In a structured prediction problem, we need to learn a predictor that can produce a structured output given a structured input (eg, part-of-speech tagging). The key learning and inference challenge is due to the exponential size of the structured output space. This paper makes four contributions towards the goal of a computationally-efficient inference and training approach for structured prediction that allows to employ complex models and to optimize for non-decomposable loss functions. First, we define a simple class of randomized greedy search (RGS) based inference procedures that leverage classification algorithms for simple outputs. Second, we develop a RGS specific learning approach for amortized inference that can quickly produce high-quality outputs for a given set of structured inputs. Third, we plug our amortized RGS inference solver inside the inner loop of parameterlearning algorithms (eg, structured SVM) to improve the speed of training. Fourth, we perform extensive experiments on diverse structured prediction tasks. Results show that our proposed approach is competitive or better than many state-ofthe-art approaches in spite of its simplicity.","tags":[],"title":"Randomized greedy search for structured prediction: amortized inference and learning","type":"publication"},{"authors":["Paul Bogdan","Fan Chen","Aryan Deshwal","Janardhan Rao Doppa","Biresh Kumar Joardar","Hai Li","Shahin Nazarian","Linghao Song","Yao Xiao"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"9244c2caba975b4dc62f834204818552","permalink":"https://aryandeshwal.github.io/publication/bogdan-2019-taming/","publishdate":"2020-09-22T03:19:27.804426Z","relpermalink":"/publication/bogdan-2019-taming/","section":"publication","summary":"To avoid rewriting software code for new computer architectures and to take advantage of the extreme heterogeneous processing, communication and storage technologies, there is an urgent need for determining the right amount and type of specialization while making a heterogeneous system as programmable and flexible as possible. To enable both programmability and flexibility in the heterogeneous computing era, we propose a novel complex network inspired model of computation and efficient optimization algorithms for determining the optimal degree of parallelization from old software code. This mathematical framework allows us to determine the required number and type of processing elements, the amount and type of deep memory hierarchy, and the degree of reconfiguration for the communication infrastructure, thus opening new avenues to performance and energy efficiency. Our framework enables heterogeneous manycore systems to autonomously adapt from traditional switching techniques to network coding strategies in order to sustain on-chip communication in the order of terabytes. While this new programming model enables the design of self-programmable autonomous heterogeneous manycore systems, a number of open challenges will be discussed.","tags":[],"title":"Taming extreme heterogeneity via machine learning based design of autonomous manycore systems","type":"publication"},{"authors":null,"categories":null,"content":"Assistant Professor in Computer Science, University of Minnesota  2024 - Present\n PhD in Computer Science, Washington State University  2018 - 2024\n Research Intern, Adaptive Experimentation Team, Meta  Summer 2022 and Summer 2023\n Research Intern, Vizier Team, Google  Summer 2021\n MS in Computer Science, Washington State University  2018 - 2020\n B.Tech. in Mathematics \u0026amp; Computing, Delhi Technological University  2013 - 2017 \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c9b5771543b03b8149b612b630936a56","permalink":"https://aryandeshwal.github.io/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/","section":"","summary":"Assistant Professor in Computer Science, University of Minnesota  2024 - Present\n PhD in Computer Science, Washington State University  2018 - 2024\n Research Intern, Adaptive Experimentation Team, Meta  Summer 2022 and Summer 2023","tags":null,"title":"Experience","type":"page"}]