[{"authors":["admin"],"categories":null,"content":"I am a PhD student in the School of Electrical Engineering and Computer Science at Washington State University. I am broadly interested in the fields of Machine Learning, Probabilistic Modeling and Optimization. The current focus of my work is on integrating learning and search techniques to efficiently and accurately solve problems that involve learning and reasoning over large space of combinatorial structures. Much of my work is motivated by important applications in science and engineering including hardware design, design of analog circuits, discovery of new materials, and molecular design. Additionally, I also work on designing Bayesian optimization algorithms for assisting decision making in expensive experimentation settings of the same real-world challenges.\nBefore grad school, I got my Bachelors in Technology (B.Tech.) degree in Mathematics and Computing from Delhi Technological University, New Delhi.\nI am very fortunate to work with my advisor Dr. Jana Doppa.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://aryandeshwal.github.io/author/aryan-deshwal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aryan-deshwal/","section":"authors","summary":"I am a PhD student in the School of Electrical Engineering and Computer Science at Washington State University. I am broadly interested in the fields of Machine Learning, Probabilistic Modeling and Optimization.","tags":null,"title":"Aryan Deshwal","type":"authors"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"359743054050ff7671318778ccdf7813","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-imoca/","publishdate":"2020-09-22T03:19:28.544737Z","relpermalink":"/publication/belakaria-2020-imoca/","section":"publication","summary":"Many real-world applications involve black-box optimization of multiple objectives using continuous function approximations that trade-off accuracy and resource cost of evaluation. For example, in rocket launching research, we need to find designs that trade-off return-time and angular distance using continuous-fidelity simulators (eg, varying tolerance parameter to trade-off simulation time and accuracy) for design evaluations. The goal is to approximate the optimal Pareto set by minimizing the cost for evaluations. In this paper, we propose a novel approach referred to as information-Theoretic Multi-Objective Bayesian Optimization with Continuous Approximations (iMOCA)} to solve this problem. The key idea is to select the sequence of input and function approximations for multiple objectives which maximize the information gain per unit cost for the optimal Pareto front. Our experiments on diverse synthetic and real-world benchmarks show that iMOCA significantly improves over existing single-fidelity methods.","tags":[],"title":"Information-Theoretic Multi-Objective Bayesian Optimization with Continuous Approximations","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"295333d5728daa4eee65a2976139db9d","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-max/","publishdate":"2020-09-22T03:19:28.544737Z","relpermalink":"/publication/belakaria-2020-max/","section":"publication","summary":"We consider the problem of constrained multi-objective blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto set of solutions satisfying a set of constraints while minimizing the number of function evaluations. For example, in aviation power system design applications, we need to find the designs that trade-off total energy and the mass while satisfying specific thresholds for motor temperature and voltage of cells. This optimization requires performing expensive computational simulations to evaluate designs. In this paper, we propose a new approach referred as {\\em Max-value Entropy Search for Multi-objective Optimization with Constraints (MESMOC)} to solve this problem. MESMOC employs an output-space entropy based acquisition function to efficiently select the sequence of inputs for evaluation to uncover high-quality pareto-set solutions while satisfying constraints.","tags":[],"title":"Max-value Entropy Search for Multi-Objective Bayesian Optimization with Constraints","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa"],"categories":[],"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"0e9cc8055f0bf41b2a977cb2b7d665ec","permalink":"https://aryandeshwal.github.io/publication/deshwal-2020-scalable/","publishdate":"2020-09-22T03:19:28.396322Z","relpermalink":"/publication/deshwal-2020-scalable/","section":"publication","summary":"We study the problem of optimizing expensive blackbox functions over combinatorial spaces (eg, sets, sequences, trees, and graphs). BOCS (Baptista and Poloczek, 2018) is a state-of-the-art Bayesian optimization method for tractable statistical models, which performs semi-definite programming based acquisition function optimization (AFO) to select the next structure for evaluation. Unfortunately, BOCS scales poorly for large number of binary and/or categorical variables. Based on recent advances in submodular relaxation (Ito and Fujimaki, 2016) for solving Binary Quadratic Programs, we study an approach referred as Parametrized Submodular Relaxation (PSR) towards the goal of improving the scalability and accuracy of solving AFO problems for BOCS model. PSR approach relies on two key ideas. First, reformulation of AFO problem as submodular relaxation with some unknown parameters, which can be solved efficiently using minimum graph cut algorithms. Second, construction of an optimization problem to estimate the unknown parameters with close approximation to the true objective. Experiments on diverse benchmark problems show significant improvements with PSR for BOCS model.","tags":[],"title":"Scalable Combinatorial Bayesian Optimization with Tractable Statistical models","type":"publication"},{"authors":["Aryan Deshwal","Syrine Belakaria","Janardhan Rao Doppa","Alan Fern"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"88610b44a62fef0adca546957ddbb222","permalink":"https://aryandeshwal.github.io/publication/deshwal-2020-optimizing/","publishdate":"2020-09-22T03:19:27.051221Z","relpermalink":"/publication/deshwal-2020-optimizing/","section":"publication","summary":"We consider the problem of optimizing expensive black-box functions over discrete spaces (e.g., sets, sequences, graphs). The key challenge is to select a sequence of combinatorial structures to evaluate, in order to identify high-performing structures as quickly as possible. Our main contribution is to introduce and evaluate a new learning-to-search framework for this problem called L2S-DISCO. The key insight is to employ search procedures guided by control knowledge at each step to select the next structure and to improve the control knowledge as new function evaluations are observed. We provide a concrete instantiation of L2S-DISCO for local search procedure and empirically evaluate it on diverse real-world benchmarks. Results show the efficacy of L2S-DISCO over state-of-the-art algorithms in solving complex optimization problems.","tags":[],"title":"Optimizing Discrete Spaces via Expensive Evaluations: A Learning to Search Framework","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Nitthilan Kannappan Jayakodi","Janardhan Rao Doppa"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"eda852a119c77f125376cbdaf593eb62","permalink":"https://aryandeshwal.github.io/publication/belakaria-2020-uncertainty/","publishdate":"2020-09-22T03:19:26.897879Z","relpermalink":"/publication/belakaria-2020-uncertainty/","section":"publication","summary":"We consider the problem of multi-objective (MO) blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto set of solutions while minimizing the number of function evaluations. For example, in hardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive simulations. We propose a novel uncertainty-aware search framework referred to as USeMO to efficiently select the sequence of inputs for evaluation to solve this problem. The selection method of USeMO consists of solving a cheap MO optimization problem via surrogate models of the true functions to identify the most promising candidates and picking the best candidate based on a measure of uncertainty. We also provide theoretical analysis to characterize the efficacy of our approach. Our experiments on several synthetic and six diverse real-world benchmark problems show that USeMO consistently outperforms the state-of-the-art algorithms.","tags":[],"title":"Uncertainty-Aware Search Framework for Multi-Objective Bayesian Optimization","type":"publication"},{"authors":["Nitthilan Kanappan Jayakodi","Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"adb1692a9c85784bf5062f8cd67085df","permalink":"https://aryandeshwal.github.io/publication/jayakodi-2020-design/","publishdate":"2020-09-22T03:19:27.353414Z","relpermalink":"/publication/jayakodi-2020-design/","section":"publication","summary":"Many real-world edge applications including object detection, robotics, and smart health are enabled by deploying deep neural networks (DNNs) on energy-constrained mobile platforms. In this article, we propose a novel approach to trade off energy and accuracy of inference at runtime using a design space called Learning Energy Accuracy Tradeoff Networks (LEANets). The key idea behind LEANets is to design classifiers of increasing complexity using pretrained DNNs to perform input-specific adaptive inference. The accuracy and energy consumption of the adaptive inference scheme depends on a set of thresholds, one for each classifier. To determine the set of threshold vectors to achieve different energy and accuracy tradeoffs, we propose a novel multiobjective optimization approach. We can select the appropriate threshold vector at runtime based on the desired tradeoff. We perform experiments on multiple pretrained DNNs including ConvNet, VGG-16, and MobileNet using diverse image classification datasets. Our results show that we get up to a 50% gain in energy for negligible loss in accuracy, and optimized LEANets achieve significantly better energy and accuracy tradeoff when compared to a state-of-the-art method referred to as Slimmable neural networks.","tags":[],"title":"Design and Optimization of Energy-Accuracy Tradeoff Networks for Mobile Platforms via Pretrained Deep Models","type":"publication"},{"authors":["Zhiyuan Zhou","Syrine Belakaria","Aryan Deshwal","Wookpyo Hong","Janardhan Rao Doppa","Partha Pratim Pande","Deukhyoun Heo"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744768,"objectID":"fd224535a9c80060fe0c8d5ce6fa0083","permalink":"https://aryandeshwal.github.io/publication/zhou-2020-design/","publishdate":"2020-09-22T03:19:27.953852Z","relpermalink":"/publication/zhou-2020-design/","section":"publication","summary":"Efficiency of power management system (PMS) is one of the key performance metrics for highly integrated system on chips (SoCs). Towards the goal of improving power efficiency of SoCs, we make two key technical contributions in this paper. First, we develop a multi-output switched-capacitor voltage regulator (SCVR) with a new flying capacitor crossing technique (FCCT) and cloud-capacitor method. Second, to optimize the design parameters of SCVR, we introduce a novel machine¬learning (ML)-inspired optimization framework to reduce the number of expensive design simulations. Simulation shows that power loss of the multi-output SCVR with FCCT is reduced by more than 40% compared to conventional multiple single-output SCVRs. Our ML-based design optimization framework is able to achieve more than 90% reduction in the number of simulations needed to uncover optimized circuit parameters of the proposed SCVR.","tags":[],"title":"Design of Multi-Output Switched-Capacitor Voltage Regulator via Machine Learning","type":"publication"},{"authors":["Syrine Belakaria","Aryan Deshwal","Janardhan Rao Doppa"],"categories":[],"content":"","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"0290f2246eae4bfabca526ce064c5075","permalink":"https://aryandeshwal.github.io/publication/belakaria-2019-max/","publishdate":"2020-09-22T03:19:27.654687Z","relpermalink":"/publication/belakaria-2019-max/","section":"publication","summary":"We consider the problem of multi-objective (MO) blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto-set of solutions by minimizing the number of function evaluations. For example, in hardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive simulations. We propose a novel approach referred to as Max-value Entropy Search for Multi-objective Optimization (MESMO) to solve this problem. MESMO employs an output-space entropy based acquisition function to efficiently select the sequence of inputs for evaluation for quickly uncovering high-quality solutions. We also provide theoretical analysis to characterize the efficacy of MESMO. Our experiments on several synthetic and real-world benchmark problems show that MESMO consistently outperforms state-of-the-art algorithms.","tags":[],"title":"Max-value Entropy Search for Multi-Objective Bayesian Optimization","type":"publication"},{"authors":["Aryan Deshwal","Nitthilan Kanappan Jayakodi","Biresh Kumar Joardar","Janardhan Rao Doppa","Partha Pratim Pande"],"categories":[],"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"51d35b8323c435d311a7763d844a52d0","permalink":"https://aryandeshwal.github.io/publication/deshwal-2019-moos/","publishdate":"2020-09-22T03:19:27.507104Z","relpermalink":"/publication/deshwal-2019-moos/","section":"publication","summary":"The growing needs of emerging applications has posed significant challenges for the design of optimized manycore systems. Network-on-Chip (NoC) enables the integration of a large number of processing elements (PEs) in a single die. To design optimized manycore systems, we need to establish suitable trade-offs among multiple objectives including power, performance, and thermal. Therefore, we consider multi-objective design space exploration (MO-DSE) problems arising in the design of NoC-enabled manycore systems: placement of PEs and communication links to optimize two or more objectives (e.g., latency, energy, and throughput). Existing algorithms to solve MO-DSE problems suffer from scalability and accuracy challenges as size of the design space and the number of objectives grow. In this paper, we propose a novel framework referred as Multi-Objective Optimistic Search (MOOS) that performs adaptive design space exploration using a data-driven model to improve the speed and accuracy of multi-objective design optimization process. We apply MOOS to design both 3D heterogeneous and homogeneous manycore systems using Rodinia, PARSEC, and SPLASH2 benchmark suites. We demonstrate that MOOS improves the speed of finding solutions compared to state-of-the-art methods by up to 13X while uncovering designs that are up to 20% better in terms of NoC. The optimized 3D manycore systems improve the EDP up to 38% when compared to 3D mesh-based designs optimized for the placement of PEs.","tags":[],"title":"MOOS: A multi-objective design space exploration and optimization framework for NoC enabled manycore systems","type":"publication"},{"authors":["Aryan Deshwal","Janardhan Rao Doppa","Dan Roth"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744766,"objectID":"2abaf7694b4cbf1967451ac686ce8a17","permalink":"https://aryandeshwal.github.io/publication/deshwal-2019-learning/","publishdate":"2020-09-22T03:19:26.612542Z","relpermalink":"/publication/deshwal-2019-learning/","section":"publication","summary":"In a structured prediction problem, one needs to learn a predictor that, given a structured input, produces a structured object, such as a sequence, tree, or clustering output. Prototypical structured prediction tasks include part-of-speech tagging (predicting POS tag sequence for an input sentence) and semantic segmentation of images (predicting semantic labels for pixels of an input image). Unlike simple classification problems, here there is a need to assign values to multiple output variables accounting for the dependencies between them. Consequently, the prediction step itself (aka “inference” or “decoding”) is computationally-expensive, and so is the learning process, that typically requires making predictions as part of it. The key learning and inference challenge is due to the exponential size of the structured output space and depend on its complexity. In this paper, we present a unifying perspective of the different frameworks that address structured prediction problems and compare them in terms of their strengths and weaknesses. We also discuss important research directions including integration of deep learning advances into structured prediction methods, and learning from weakly supervised signals and active querying to overcome the challenges of building structured predictors from small amount of labeled data.","tags":[],"title":"Learning and inference for structured prediction: a unifying perspective","type":"publication"},{"authors":["Chao Ma","FA Rezaur Rahman Chowdhury","Aryan Deshwal","Md Rakibul Islam","Janardhan Rao Doppa","Dan Roth"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"612ea79ca4b8ed761a5a0042b3e71ece","permalink":"https://aryandeshwal.github.io/publication/ma-2019-randomized/","publishdate":"2020-09-22T03:19:27.20383Z","relpermalink":"/publication/ma-2019-randomized/","section":"publication","summary":"In a structured prediction problem, we need to learn a predictor that can produce a structured output given a structured input (eg, part-of-speech tagging). The key learning and inference challenge is due to the exponential size of the structured output space. This paper makes four contributions towards the goal of a computationally-efficient inference and training approach for structured prediction that allows to employ complex models and to optimize for non-decomposable loss functions. First, we define a simple class of randomized greedy search (RGS) based inference procedures that leverage classification algorithms for simple outputs. Second, we develop a RGS specific learning approach for amortized inference that can quickly produce high-quality outputs for a given set of structured inputs. Third, we plug our amortized RGS inference solver inside the inner loop of parameterlearning algorithms (eg, structured SVM) to improve the speed of training. Fourth, we perform extensive experiments on diverse structured prediction tasks. Results show that our proposed approach is competitive or better than many state-ofthe-art approaches in spite of its simplicity.","tags":[],"title":"Randomized greedy search for structured prediction: amortized inference and learning","type":"publication"},{"authors":["Paul Bogdan","Fan Chen","Aryan Deshwal","Janardhan Rao Doppa","Biresh Kumar Joardar","Hai Li","Shahin Nazarian","Linghao Song","Yao Xiao"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600744767,"objectID":"9244c2caba975b4dc62f834204818552","permalink":"https://aryandeshwal.github.io/publication/bogdan-2019-taming/","publishdate":"2020-09-22T03:19:27.804426Z","relpermalink":"/publication/bogdan-2019-taming/","section":"publication","summary":"To avoid rewriting software code for new computer architectures and to take advantage of the extreme heterogeneous processing, communication and storage technologies, there is an urgent need for determining the right amount and type of specialization while making a heterogeneous system as programmable and flexible as possible. To enable both programmability and flexibility in the heterogeneous computing era, we propose a novel complex network inspired model of computation and efficient optimization algorithms for determining the optimal degree of parallelization from old software code. This mathematical framework allows us to determine the required number and type of processing elements, the amount and type of deep memory hierarchy, and the degree of reconfiguration for the communication infrastructure, thus opening new avenues to performance and energy efficiency. Our framework enables heterogeneous manycore systems to autonomously adapt from traditional switching techniques to network coding strategies in order to sustain on-chip communication in the order of terabytes. While this new programming model enables the design of self-programmable autonomous heterogeneous manycore systems, a number of open challenges will be discussed.","tags":[],"title":"Taming extreme heterogeneity via machine learning based design of autonomous manycore systems","type":"publication"}]